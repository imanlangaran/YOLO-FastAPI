{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Note Book is same as app.py file\n",
    "I just used Note Book features to implement its functions :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "# from ultralytics.yolo.utils.plotting import Annotator, colors\n",
    "from ultralytics.utils.plotting import Annotator, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('models/yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\projects\\Python\\YOLO-FastAPI\\bus.jpg: 640x480 3 persons, 1 bus, 184.0ms\n",
      "Speed: 23.0ms preprocess, 184.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(source='bus.jpg', conf=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     22.871,      231.28,         805,      756.84],\n",
       "       [      48.55,      398.55,      245.35,       902.7],\n",
       "       [     669.47,      392.19,      809.72,      877.04],\n",
       "       [     221.52,       405.8,      344.97,      857.54]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].to('cpu').numpy().boxes.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = pd.DataFrame(result[0].to('cpu').numpy().boxes.xyxy, columns=['x1', 'y1', 'x2', 'y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes['confs'] = result[0].to('cpu').numpy().boxes.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes['classes'] = (result[0].to('cpu').numpy().boxes.cls).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes['classes'] = bboxes['classes'].replace(result[0].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>confs</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.871269</td>\n",
       "      <td>231.277313</td>\n",
       "      <td>805.002686</td>\n",
       "      <td>756.840454</td>\n",
       "      <td>0.873449</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.550465</td>\n",
       "      <td>398.552216</td>\n",
       "      <td>245.345596</td>\n",
       "      <td>902.702698</td>\n",
       "      <td>0.865691</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>669.472900</td>\n",
       "      <td>392.185974</td>\n",
       "      <td>809.720032</td>\n",
       "      <td>877.035461</td>\n",
       "      <td>0.852835</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221.517288</td>\n",
       "      <td>405.798645</td>\n",
       "      <td>344.970612</td>\n",
       "      <td>857.536621</td>\n",
       "      <td>0.825224</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          y1          x2          y2     confs classes\n",
       "0   22.871269  231.277313  805.002686  756.840454  0.873449     bus\n",
       "1   48.550465  398.552216  245.345596  902.702698  0.865691  person\n",
       "2  669.472900  392.185974  809.720032  877.035461  0.852835  person\n",
       "3  221.517288  405.798645  344.970612  857.536621  0.825224  person"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key function 1\n",
    "\n",
    "model = YOLO('models/yolov8n.pt')\n",
    "def get_predict_df(file : Image) -> pd.DataFrame:\n",
    "    # model = YOLO('models/yolov8n.pt')\n",
    "\n",
    "    result = model.predict(source=file, conf=0.6)\n",
    "    bboxes = pd.DataFrame(result[0].to('cpu').numpy().boxes.xyxy, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "    bboxes['conf'] = result[0].to('cpu').numpy().boxes.conf\n",
    "    bboxes['class'] = (result[0].to('cpu').numpy().boxes.cls).astype(int)\n",
    "    bboxes['name'] = bboxes['class'].replace(result[0].names)\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('bus.jpg').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 3 persons, 1 bus, 209.0ms\n",
      "Speed: 8.0ms preprocess, 209.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "preds = get_predict_df(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img = draw_boxes(img=img, preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = Annotator(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.sort_values(by=['x1'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in preds.iterrows():\n",
    "    # print(f\"index= {i}\")\n",
    "    # print(f\"data:\\n{data}\")\n",
    "    # print('##########\\n')\n",
    "    annotator.box_label(\n",
    "        box=[\n",
    "            data['x1'],data['y1'],\n",
    "            data['x2'],data['y2']\n",
    "        ],\n",
    "        label=f\"{data['name']}: {data['conf']:.2f}\", \n",
    "        color=colors(data['class'], bgr=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img2 = Image.fromarray(annotator.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key function 2\n",
    "\n",
    "def draw_boxes(img : Image, preds:pd.DataFrame) -> Image:\n",
    "    annotator = Annotator(np.array(img))\n",
    "    preds = preds.sort_values(by=['x1'], ascending=True)\n",
    "    for i, data in preds.iterrows():\n",
    "        annotator.box_label(\n",
    "            box=[\n",
    "                data['x1'],data['y1'],\n",
    "                data['x2'],data['y2']\n",
    "            ],\n",
    "            label=f\"{data['name']}: {data['conf']:.2f}\", \n",
    "            color=colors(data['class'], bgr=True))\n",
    "    return Image.fromarray(annotator.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = YOLO('models/yolov8n-seg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key function 3\n",
    "def get_segmented_img(file:Image) -> Image:\n",
    "    result = seg_model.predict(source=file, conf=0.6)[0]\n",
    "    out_img = Image.fromarray(result.plot()[..., ::-1])\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('pics/bus.jpg').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 3 persons, 1 bus, 236.1ms\n",
      "Speed: 6.0ms preprocess, 236.1ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "out_img = get_segmented_img(file=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 3 persons, 1 bus, 978.7ms\n",
      "Speed: 332.7ms preprocess, 978.7ms inference, 311.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "result = seg_model.predict(source=img, conf=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = result[0]\n",
    "im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "im.show()  # show image\n",
    "# im.save('results.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model = YOLO('models/yolov8n-cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('pics/bus.jpg').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 minibus 0.47, police_van 0.25, ambulance 0.05, recreational_vehicle 0.04, bullet_train 0.02, 600.7ms\n",
      "Speed: 389.6ms preprocess, 600.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "result = class_model.predict(source=img, conf=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Probs object with attributes:\n",
       "\n",
       "data: tensor([2.2782e-07, 3.9835e-07, 1.8025e-05, 1.2990e-06, 4.0058e-05, 4.2587e-06, 1.5845e-06, 5.4020e-06, 1.4168e-07, 1.0631e-06, 1.3268e-08, 5.1390e-08, 5.9792e-08, 4.9972e-09, 3.2175e-07, 3.0764e-08, 4.8649e-09, 1.1995e-06, 8.7467e-07, 5.7113e-08, 2.0526e-09, 7.0013e-08, 1.6223e-07, 1.2153e-07, 3.2795e-08, 1.7966e-07,\n",
       "        2.7880e-08, 2.7480e-08, 6.9575e-08, 2.4716e-06, 1.9853e-07, 7.1315e-09, 9.2888e-08, 1.1460e-05, 2.4519e-05, 2.9449e-07, 9.7188e-07, 2.1076e-07, 1.8162e-08, 2.7766e-06, 8.3557e-08, 1.0282e-07, 1.3435e-07, 9.6201e-08, 1.0423e-07, 2.0541e-06, 1.0941e-07, 1.2530e-07, 3.9443e-06, 6.0217e-07, 4.4510e-06, 2.0545e-05,\n",
       "        1.6594e-07, 7.0468e-08, 2.3901e-07, 1.1954e-07, 3.0200e-07, 2.0979e-08, 1.1534e-07, 1.8255e-07, 3.8974e-06, 7.5831e-06, 4.5554e-06, 1.1325e-06, 8.9009e-07, 2.7293e-06, 4.6082e-08, 9.5021e-06, 5.4790e-08, 2.2610e-08, 1.3181e-09, 3.7680e-07, 2.9976e-08, 6.0336e-08, 6.4248e-08, 9.7971e-09, 2.7124e-06, 1.1459e-07,\n",
       "        2.1204e-07, 6.7224e-07, 1.3836e-07, 7.7435e-08, 3.1261e-08, 5.6044e-08, 7.2073e-06, 2.0889e-07, 5.5417e-08, 7.7038e-07, 3.4878e-07, 2.2339e-06, 1.4972e-07, 4.3087e-07, 1.4492e-08, 3.2099e-07, 4.9841e-08, 2.1109e-08, 6.0600e-07, 1.3908e-07, 4.3850e-08, 4.6761e-06, 4.9177e-07, 9.2803e-06, 3.6286e-07, 5.3563e-08,\n",
       "        7.3204e-07, 1.2881e-06, 1.1355e-06, 1.5270e-07, 2.7319e-08, 3.9967e-07, 6.8860e-09, 6.0545e-08, 5.3762e-06, 7.7264e-08, 2.0916e-07, 1.7388e-08, 3.3661e-08, 1.7756e-08, 4.9665e-06, 2.6556e-06, 1.1433e-06, 2.3511e-06, 3.4943e-07, 2.7422e-07, 5.8691e-06, 1.9625e-07, 1.0154e-06, 2.8501e-07, 3.1035e-08, 1.4667e-07,\n",
       "        1.2270e-07, 9.6786e-08, 1.1505e-06, 3.4687e-09, 2.0028e-06, 1.3582e-08, 3.6658e-07, 2.3442e-07, 2.5382e-07, 4.1644e-08, 1.1702e-08, 7.1959e-09, 2.5426e-09, 3.6086e-08, 3.4639e-06, 1.8131e-06, 1.4788e-07, 4.3209e-06, 4.9426e-05, 1.3610e-06, 1.6619e-05, 1.1444e-05, 2.2288e-07, 8.5865e-07, 7.4785e-06, 1.6544e-06,\n",
       "        6.9674e-07, 9.8877e-07, 4.5461e-06, 4.1972e-06, 3.6029e-06, 1.1753e-06, 1.2536e-06, 2.8379e-05, 3.9174e-06, 3.4463e-06, 7.6312e-07, 6.2573e-07, 4.5065e-06, 2.7257e-05, 2.4962e-04, 1.2089e-05, 2.1079e-05, 1.7078e-05, 3.9814e-06, 1.1590e-06, 1.9740e-05, 8.1556e-05, 3.7116e-06, 4.9149e-05, 3.9300e-05, 1.2828e-06,\n",
       "        3.6259e-06, 4.4689e-06, 1.2542e-05, 5.6465e-06, 7.6450e-06, 1.0491e-06, 2.1480e-06, 6.1636e-06, 5.7239e-06, 8.0414e-07, 2.1500e-05, 2.1315e-06, 2.3189e-06, 2.2706e-05, 5.3435e-06, 1.9378e-05, 4.1642e-05, 1.2630e-05, 4.0430e-07, 1.2173e-06, 1.2124e-05, 1.9240e-04, 1.4365e-06, 5.0871e-05, 2.1503e-05, 4.5387e-06,\n",
       "        7.5926e-05, 1.3799e-05, 3.0812e-06, 2.3090e-05, 1.3088e-05, 8.6771e-06, 7.2153e-06, 3.8842e-06, 3.1512e-05, 3.4982e-06, 6.1080e-07, 8.0707e-07, 2.6343e-06, 2.9388e-06, 5.1915e-06, 7.2453e-05, 4.6959e-05, 4.8391e-05, 1.3226e-05, 8.7976e-06, 1.2139e-05, 1.0018e-05, 4.4955e-06, 7.8776e-06, 3.7654e-06, 4.5269e-05,\n",
       "        2.3873e-05, 8.4121e-06, 4.3775e-06, 1.8938e-05, 1.1887e-05, 3.1707e-06, 3.3362e-06, 3.7260e-06, 6.1729e-06, 3.1589e-05, 2.1462e-05, 4.3328e-05, 6.4750e-05, 8.9423e-06, 4.1909e-06, 3.3971e-06, 1.9824e-06, 7.6570e-05, 3.4180e-06, 2.2589e-06, 3.9203e-04, 8.3525e-05, 4.3063e-05, 2.1765e-05, 7.7343e-06, 3.4613e-06,\n",
       "        9.2666e-06, 1.2281e-06, 5.3257e-06, 4.1570e-07, 4.4538e-06, 6.7961e-06, 4.3209e-06, 1.6031e-05, 7.9382e-06, 1.1190e-06, 5.9263e-06, 1.1633e-06, 1.1914e-06, 7.4281e-06, 5.8149e-08, 1.2262e-07, 5.4194e-07, 1.1630e-07, 8.3388e-08, 1.6815e-07, 6.8375e-07, 2.0937e-06, 6.1082e-07, 7.1148e-07, 5.7333e-06, 1.2313e-06,\n",
       "        2.7752e-07, 6.5247e-08, 1.6818e-07, 6.1821e-08, 8.1271e-08, 2.7590e-07, 4.3154e-07, 2.5887e-07, 1.5516e-07, 1.2169e-06, 1.2796e-06, 2.2424e-07, 1.1868e-07, 1.5832e-07, 6.1788e-09, 4.7455e-08, 1.3523e-07, 1.3002e-08, 2.1323e-08, 4.4668e-07, 3.1114e-07, 2.8818e-08, 3.0751e-08, 2.1056e-07, 4.0539e-08, 1.0749e-07,\n",
       "        8.4880e-08, 1.1973e-07, 2.9117e-07, 2.0008e-08, 3.2094e-08, 2.6707e-08, 1.3928e-08, 3.1265e-08, 1.5047e-08, 1.2746e-08, 1.3927e-09, 6.2400e-09, 9.5997e-09, 9.1977e-09, 7.5264e-10, 4.7888e-07, 3.8238e-07, 1.3361e-06, 1.7157e-07, 1.1819e-06, 4.6403e-06, 7.7193e-08, 5.5691e-07, 1.7875e-08, 3.9739e-07, 8.7070e-07,\n",
       "        2.3163e-07, 2.7761e-06, 9.2339e-06, 1.5650e-04, 1.0929e-05, 1.6934e-05, 1.5066e-06, 8.6289e-05, 3.0077e-05, 3.7143e-05, 3.7813e-05, 7.1845e-06, 1.1979e-06, 1.1940e-08, 3.5693e-08, 2.7704e-07, 3.9674e-05, 1.4314e-04, 3.0152e-07, 1.1910e-07, 7.0578e-07, 1.2496e-06, 2.2500e-06, 2.7036e-06, 3.2590e-07, 2.3014e-06,\n",
       "        5.0301e-08, 5.8546e-07, 1.3109e-06, 1.2281e-05, 1.4690e-07, 1.3267e-06, 1.1290e-07, 2.2917e-07, 2.3216e-06, 3.9112e-06, 9.7005e-07, 5.2922e-08, 3.9597e-08, 7.0632e-08, 1.9856e-07, 1.1000e-07, 1.1886e-07, 4.0832e-07, 4.4228e-08, 6.7327e-08, 1.9560e-08, 9.6582e-05, 8.0290e-05, 1.6331e-08, 6.2772e-08, 1.2201e-05,\n",
       "        1.1453e-06, 1.2101e-04, 1.2664e-07, 7.0583e-09, 4.4888e-05, 5.2991e-05, 6.9419e-08, 2.3912e-06, 1.5534e-06, 5.8383e-06, 1.6526e-05, 8.9101e-05, 4.0347e-06, 7.2913e-05, 5.3332e-05, 3.1848e-05, 7.6870e-06, 4.9342e-02, 1.5493e-02, 5.8064e-06, 3.6045e-06, 3.7825e-06, 5.8449e-04, 3.9066e-05, 3.0692e-05, 9.6392e-06,\n",
       "        4.3078e-05, 1.5988e-05, 8.3609e-07, 3.7327e-06, 7.9733e-06, 8.8417e-06, 1.0708e-05, 2.5514e-06, 1.9776e-05, 1.3715e-06, 3.0741e-07, 1.0424e-04, 1.8988e-04, 7.0515e-06, 2.0939e-06, 3.4947e-06, 1.9292e-05, 8.8459e-05, 7.2544e-07, 3.7200e-06, 9.3949e-04, 4.5406e-07, 7.1390e-07, 3.0140e-05, 3.3005e-06, 1.3118e-06,\n",
       "        1.1135e-05, 1.1894e-07, 4.6861e-05, 6.9392e-06, 1.7797e-06, 1.7511e-05, 7.0931e-07, 1.0317e-05, 4.9148e-04, 1.4683e-06, 6.5430e-06, 4.3934e-06, 2.4985e-05, 1.1981e-06, 4.4281e-05, 8.5058e-06, 5.7199e-06, 6.3650e-06, 3.2331e-06, 9.2350e-06, 2.4526e-05, 3.1606e-06, 1.8462e-07, 3.4282e-05, 2.4124e-02, 5.1658e-06,\n",
       "        8.5391e-04, 2.0107e-05, 4.2366e-07, 2.7661e-05, 4.7090e-05, 1.5434e-07, 1.0591e-06, 7.7945e-06, 9.7734e-06, 1.5216e-05, 1.9003e-04, 2.6079e-04, 3.9102e-04, 1.4679e-06, 3.5606e-05, 2.0521e-06, 1.8328e-04, 3.8701e-06, 3.1511e-06, 2.9215e-05, 5.1919e-06, 6.4142e-06, 1.6603e-05, 3.1759e-05, 7.2188e-06, 1.0167e-06,\n",
       "        1.0863e-06, 1.7569e-06, 3.6009e-07, 4.6461e-06, 1.0828e-05, 1.3417e-06, 6.6297e-07, 6.8879e-06, 5.4715e-06, 2.4063e-07, 8.8882e-07, 5.7248e-07, 4.5910e-07, 1.8128e-07, 2.4686e-06, 9.3518e-06, 5.5370e-06, 1.8450e-04, 2.7123e-07, 8.0505e-05, 2.4884e-05, 1.5158e-04, 9.2678e-07, 1.0170e-04, 3.1964e-04, 7.7355e-05,\n",
       "        4.4493e-06, 3.3451e-06, 3.9686e-06, 2.4772e-04, 2.7172e-06, 2.5400e-07, 1.8049e-05, 1.6627e-05, 1.2023e-06, 3.1047e-06, 1.0583e-05, 5.5135e-06, 1.9327e-06, 8.3844e-08, 1.1448e-05, 2.1757e-07, 7.0081e-05, 4.8328e-06, 1.1393e-05, 5.6099e-06, 1.7514e-05, 3.8990e-05, 4.7920e-06, 3.9802e-06, 1.6119e-05, 5.6832e-06,\n",
       "        3.7789e-06, 4.0861e-04, 1.0431e-05, 2.5214e-07, 2.3985e-07, 1.1002e-07, 4.8334e-05, 1.2965e-05, 2.5575e-06, 8.1389e-04, 1.0945e-06, 2.6646e-05, 1.9679e-05, 1.0195e-05, 3.0069e-05, 8.5017e-04, 1.2024e-05, 6.8447e-07, 2.0546e-06, 1.3578e-05, 4.5232e-06, 7.0999e-07, 8.3937e-05, 2.0965e-03, 1.8214e-05, 1.1328e-04,\n",
       "        4.4157e-07, 1.1879e-05, 1.4183e-07, 4.7159e-03, 1.5446e-06, 1.8517e-06, 7.5378e-06, 2.9214e-05, 1.7108e-05, 1.9402e-04, 5.8865e-05, 3.6645e-06, 7.8330e-08, 1.3627e-05, 1.0472e-03, 3.7573e-06, 8.1414e-07, 6.1734e-06, 3.4384e-06, 1.6712e-05, 6.4624e-07, 3.6734e-05, 1.1224e-06, 1.1670e-04, 2.3778e-06, 3.2250e-07,\n",
       "        2.7124e-05, 2.2159e-07, 5.5098e-06, 1.0691e-05, 1.0271e-05, 6.0783e-04, 2.6308e-07, 9.6315e-06, 4.6807e-06, 5.9052e-07, 1.3103e-04, 2.2811e-02, 9.3615e-06, 3.4974e-06, 3.1230e-03, 1.4111e-06, 9.0791e-06, 1.4473e-05, 5.8421e-07, 6.7860e-05, 6.7198e-07, 1.9270e-07, 1.6760e-05, 2.6420e-05, 7.7313e-07, 3.1822e-08,\n",
       "        1.0569e-05, 5.6712e-05, 1.2770e-07, 2.1015e-02, 6.6183e-05, 1.1724e-07, 7.7984e-06, 9.6921e-07, 4.2384e-05, 6.4933e-08, 2.0059e-04, 2.7662e-07, 8.7623e-06, 3.2115e-04, 1.7260e-05, 2.0910e-06, 1.2462e-06, 7.9474e-06, 5.7142e-06, 1.4673e-06, 9.4213e-08, 4.3829e-06, 5.5906e-05, 4.2718e-07, 2.4740e-07, 1.1251e-06,\n",
       "        4.6413e-06, 6.0269e-06, 1.9513e-03, 1.0063e-05, 4.6690e-01, 2.3596e-03, 1.7291e-02, 4.4707e-04, 1.5505e-07, 1.7278e-07, 6.8714e-04, 3.3981e-03, 2.1733e-06, 4.7111e-06, 6.6078e-05, 2.1077e-05, 1.7894e-06, 2.5887e-05, 1.1254e-05, 2.6966e-06, 6.6051e-05, 4.2610e-05, 1.0008e-05, 2.4532e-07, 4.6134e-07, 4.5366e-03,\n",
       "        3.9530e-06, 4.2852e-07, 7.2601e-05, 2.4841e-09, 7.5512e-07, 1.1819e-05, 4.9694e-06, 6.2219e-06, 4.3316e-05, 5.6346e-07, 6.8915e-07, 5.6369e-07, 3.8900e-06, 4.5071e-07, 4.2162e-04, 5.5825e-05, 4.1805e-07, 1.5273e-05, 2.8373e-06, 6.7413e-07, 3.9294e-06, 7.3688e-06, 7.6694e-06, 3.1607e-06, 1.3156e-05, 3.7511e-05,\n",
       "        7.0920e-05, 5.3517e-05, 1.0956e-04, 1.3136e-02, 1.8253e-05, 7.8965e-05, 4.9527e-06, 3.2304e-06, 8.1988e-08, 2.7982e-07, 9.7423e-08, 1.8311e-05, 5.8451e-08, 6.7454e-05, 1.2007e-05, 1.4525e-03, 5.6892e-06, 1.1129e-05, 2.9003e-07, 2.1652e-06, 2.0921e-05, 2.7236e-07, 2.8239e-06, 1.3747e-06, 6.9769e-08, 4.1345e-05,\n",
       "        1.0384e-04, 5.7214e-08, 1.2541e-04, 5.0714e-05, 6.8689e-07, 9.7067e-05, 2.4603e-01, 1.2053e-04, 6.2888e-06, 4.9626e-06, 2.1956e-06, 2.7985e-06, 1.6533e-05, 2.9777e-06, 5.7930e-05, 1.2636e-05, 8.0918e-04, 2.9093e-06, 3.9479e-06, 2.2335e-05, 4.5889e-07, 2.6660e-07, 1.2301e-05, 1.8062e-03, 1.4883e-05, 2.8304e-06,\n",
       "        1.0570e-05, 4.6487e-06, 3.3990e-04, 4.2209e-02, 8.9842e-06, 3.2310e-06, 2.4163e-05, 6.5982e-07, 1.4938e-05, 6.1289e-06, 3.2863e-05, 1.6750e-06, 3.0137e-05, 4.2597e-07, 1.0538e-05, 1.4395e-06, 2.8377e-06, 6.6286e-06, 5.1299e-06, 1.3924e-07, 7.8190e-07, 4.1153e-05, 2.0014e-05, 2.3653e-06, 6.2333e-06, 1.0558e-03,\n",
       "        8.3225e-07, 1.4167e-05, 4.4994e-05, 5.4125e-07, 4.1493e-06, 2.5262e-06, 1.7933e-05, 2.1390e-05, 1.2116e-05, 3.8228e-07, 3.6910e-05, 4.8228e-04, 8.7240e-05, 4.3741e-06, 1.2597e-06, 7.4173e-05, 1.0587e-05, 2.1688e-05, 7.5672e-08, 1.2425e-04, 2.5938e-06, 5.4311e-05, 9.9045e-05, 7.1887e-05, 5.7412e-07, 2.3169e-05,\n",
       "        1.0662e-06, 3.1448e-05, 3.0829e-05, 6.2289e-08, 7.4254e-06, 5.9006e-06, 3.6655e-04, 1.5094e-06, 2.6869e-05, 3.1756e-07, 1.9512e-07, 1.7280e-04, 9.6688e-06, 1.0970e-04, 3.2837e-04, 6.3952e-06, 4.3978e-05, 7.4768e-07, 7.4817e-06, 1.2931e-06, 3.3598e-06, 5.5552e-06, 4.5904e-07, 1.5043e-02, 9.5721e-04, 6.2313e-06,\n",
       "        5.4602e-06, 4.4457e-05, 1.5020e-05, 2.9111e-06, 4.0654e-05, 7.6215e-05, 2.4069e-05, 2.8445e-06, 3.0642e-05, 1.1562e-05, 5.1003e-05, 1.6125e-05, 8.6022e-07, 2.4649e-06, 3.0207e-07, 1.0404e-04, 1.4996e-05, 1.9100e-06, 4.2164e-06, 6.8638e-05, 1.7240e-05, 2.6581e-05, 1.6041e-06, 8.2417e-08, 2.1711e-04, 2.6379e-06,\n",
       "        5.3447e-07, 6.8958e-06, 5.7814e-06, 7.0828e-07, 3.3084e-05, 4.5835e-06, 2.2840e-03, 7.3452e-05, 1.7381e-04, 9.3735e-04, 2.6010e-06, 6.8533e-05, 9.7672e-05, 2.2291e-05, 2.4314e-05, 3.1118e-05, 5.6075e-03, 1.3151e-05, 1.7451e-05, 7.2416e-05, 2.6225e-06, 1.3736e-03, 4.4484e-04, 2.9092e-05, 9.4739e-05, 1.4234e-06,\n",
       "        2.1557e-06, 1.0392e-06, 4.8596e-05, 1.2147e-06, 6.1755e-06, 6.9241e-06, 1.0715e-05, 1.2917e-07, 1.5823e-06, 1.2195e-06, 1.0002e-05, 6.1304e-04, 4.2226e-07, 4.2183e-05, 3.3104e-05, 1.7785e-05, 1.0700e-06, 8.6660e-08, 1.1440e-05, 1.0769e-05, 1.3149e-06, 3.6390e-07, 4.7684e-07, 5.6769e-07, 9.2150e-05, 5.6166e-07,\n",
       "        2.3099e-06, 2.4412e-06, 6.5348e-06, 6.7038e-06, 4.4155e-07, 4.7961e-04, 7.5661e-05, 2.9644e-06, 1.2291e-06, 3.5834e-05, 1.6776e-05, 1.2450e-06, 2.0198e-07, 9.8756e-08, 1.8499e-07, 1.7888e-08, 4.9366e-08, 8.7655e-08, 1.4514e-07, 6.8208e-05, 4.6525e-07, 8.9948e-07, 1.3482e-05, 4.4828e-08, 2.7210e-06, 7.4800e-08,\n",
       "        1.6560e-06, 3.2846e-07, 2.6108e-06, 3.6499e-07, 5.3189e-08, 3.6211e-08, 6.1486e-08, 2.9781e-07, 1.1921e-07, 3.2958e-08, 3.6681e-08, 7.0653e-08, 6.0591e-07, 3.1110e-07, 3.0526e-06, 6.6409e-07, 1.8460e-07, 4.5806e-07, 1.5222e-05, 3.1412e-06, 1.6047e-06, 1.6473e-07, 1.9613e-05, 1.8880e-07, 3.3803e-08, 5.4538e-07,\n",
       "        1.8357e-07, 2.3297e-07, 9.4734e-08, 3.0987e-07, 1.3503e-07, 1.0879e-07, 4.6112e-07, 2.6202e-08, 1.7308e-04, 1.5979e-04, 2.4311e-06, 1.8853e-06, 4.2438e-06, 5.3205e-05, 3.5797e-06, 4.0665e-04, 9.9302e-06, 2.5261e-06, 4.7947e-05, 6.3251e-05, 5.9383e-04, 1.2080e-05, 2.9965e-06, 2.7164e-08, 3.1878e-09, 1.6102e-06,\n",
       "        3.1492e-08, 2.0304e-08, 6.6590e-09, 1.0129e-08, 1.4333e-08, 2.0647e-09, 4.3897e-09, 7.1463e-08, 8.7834e-08, 1.2223e-08, 5.6085e-06, 8.0563e-06])\n",
       "orig_shape: None\n",
       "shape: torch.Size([1000])\n",
       "top1: 654\n",
       "top1conf: tensor(0.4669)\n",
       "top5: [654, 734, 407, 757, 466]\n",
       "top5conf: tensor([0.4669, 0.2460, 0.0493, 0.0422, 0.0241])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[654, 734, 407, 757, 466]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].to('cpu').numpy().probs.top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.DataFrame(result[0].to('cpu').numpy().probs.top5, columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes['conf'] = result[0].to('cpu').numpy().probs.top5conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes['name'] = classes['class'].replace(result[0].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conf</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>654</td>\n",
       "      <td>0.466905</td>\n",
       "      <td>minibus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>734</td>\n",
       "      <td>0.246027</td>\n",
       "      <td>police_van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>407</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>ambulance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>757</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>recreational_vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>bullet_train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class      conf                  name\n",
       "0    654  0.466905               minibus\n",
       "1    734  0.246027            police_van\n",
       "2    407  0.049342             ambulance\n",
       "3    757  0.042209  recreational_vehicle\n",
       "4    466  0.024124          bullet_train"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model = YOLO('models/yolov8n-cls.pt')\n",
    "\n",
    "def get_class_df(file:Image) -> pd.DataFrame:\n",
    "    result = class_model.predict(source=file, conf=0.6)\n",
    "    classes = pd.DataFrame(result[0].to('cpu').numpy().probs.top5, columns=['class'])\n",
    "    classes['conf'] = result[0].to('cpu').numpy().probs.top5conf\n",
    "    classes['name'] = classes['class'].replace(result[0].names)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('pics/bus.jpg').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 minibus 0.47, police_van 0.25, ambulance 0.05, recreational_vehicle 0.04, bullet_train 0.02, 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conf</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>654</td>\n",
       "      <td>0.466905</td>\n",
       "      <td>minibus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>734</td>\n",
       "      <td>0.246027</td>\n",
       "      <td>police_van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>407</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>ambulance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>757</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>recreational_vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>bullet_train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class      conf                  name\n",
       "0    654  0.466905               minibus\n",
       "1    734  0.246027            police_van\n",
       "2    407  0.049342             ambulance\n",
       "3    757  0.042209  recreational_vehicle\n",
       "4    466  0.024124          bullet_train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = get_class_df(file=img)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model = YOLO('models/yolov8n-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('pics/bus.jpg').convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 839.8ms\n",
      "Speed: 158.8ms preprocess, 839.8ms inference, 362.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "result = pose_model.predict(source=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = Annotator(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in reversed(result[0].keypoints.data):\n",
    "            annotator.kpts(k, result[0].orig_shape, radius=5, kpt_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotator.kpts(kpts, shape=result[0].orig_shape, radius=5, kpt_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Image.fromarray(annotator.result())\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key function\n",
    "pose_model = YOLO('models/yolov8n-pose.pt')\n",
    "\n",
    "def get_posed_img(file:Image) ->Image:\n",
    "    result = pose_model.predict(source=file)\n",
    "    annotator = Annotator(np.array(file))\n",
    "    for k in reversed(result[0].keypoints.data):\n",
    "        annotator.kpts(k, result[0].orig_shape, radius=5, kpt_line=True)\n",
    "    return Image.fromarray(annotator.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('pics/bus.jpg').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 199.0ms\n",
      "Speed: 5.2ms preprocess, 199.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "out = get_posed_img(file=img)\n",
    "out.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
